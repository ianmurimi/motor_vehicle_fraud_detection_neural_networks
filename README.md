This project focuses on binary classification for motor vehicle insurance claims, where the objective is to categorize each claim as either Fraud (1) or Non-fraud (0). The training dataset is highly imbalanced, with 6,091 instances labeled as non-fraud and only 372 labeled as fraud. To address this imbalance, a combination of techniques has been applied to generate synthetic fraud images and create a more balanced dataset for training.

To tackle the challenge of limited fraud data, traditional data augmentation methods were used alongside Generative Adversarial Networks (GANs). GANs were employed to generate synthetic fraud images, enriching the minority class with realistic yet artificially created examples. Additionally, SMOTE (Synthetic Minority Oversampling Technique) was used to further address the imbalance by generating synthetic samples from the existing fraud cases. These approaches help ensure that the model does not become biased toward the majority class and performs better in predicting fraudulent cases.

The dataset used for this project is publicly available on Kaggle: Vehicle Insurance Fraud Classification. Various data balancing techniques, such as GAN, SMOTE, and traditional augmentation, were implemented to ensure that the model can learn effectively from both the minority and majority classes.

This project highlights the importance of addressing data imbalance in fraud detection tasks. By generating synthetic fraud samples, the model becomes more robust, improving its ability to detect fraudulent claims without being overwhelmed by the dominant non-fraud class. This balanced approach leads to better generalization and more accurate predictions when deployed in real-world scenarios.
